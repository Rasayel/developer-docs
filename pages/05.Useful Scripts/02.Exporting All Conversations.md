# A Beginner's Guide to Exporting All Conversations

Welcome! In this tutorial, we'll guide you through the process of exporting all textual data from your conversations using a Ruby script. Don't worry if you're new to Ruby, this tutorial is beginner-friendly and can help you understand how the process works, which can be adapted to other programming languages as well.

We'll be using the query described in the [List All Conversations](/common-api-queries/list-all-conversations) guide.

## Installing Ruby

Before we begin, make sure you have Ruby installed on your computer. If you don't have it already, you can follow these instructions:

- Windows: Install Ruby using RubyInstaller, available here: https://www.ruby-lang.org/en/documentation/installation/#rubyinstaller
- MacOS / Linux: Install Ruby using rbenv, available here: https://www.ruby-lang.org/en/documentation/installation/#rbenv

Alternatively, if you don't want to install Ruby on your computer, you can use an online tool like [Replit](https://replit.com/languages/ruby) to write and run Ruby code in your browser.

## Script

To get started, you'll need to obtain your Access Token and include it in the script. Without it, the script **won't work**. To learn how to find your Access Token, refer to our [Quickstart](/introduction/quickstart) guide. Once you have your Access Token, you're all set to start exporting your conversations! Good luck, and happy coding!

This Ruby script fetches and exports all conversations and their messages. Let's break it down into sections and explain what each section does:

**1. Loading required libraries and setting up constants**

```ruby
require "uri"
require "net/http"
require "openssl"
require "json"

ACCESS_TOKEN = "YOUR ACCESS TOKEN GOES HERE" # Your Access Token goes here
URL = URI("https://api.rasayel.io/api/graphql")
```

This section loads the required libraries for handling HTTP requests, SSL, JSON, and URIs. It also sets up the ACCESS_TOKEN and the URL constants. You need to replace "YOUR ACCESS TOKEN GOES HERE" with your actual access token.

**2. Defining GraphQL fragments and queries**

```ruby
PAGE_INFO_FRAGMENT = <<~GRAPHQL
  fragment PageInfoFields on PageInfo {
    hasNextPage
    endCursor
  }
GRAPHQL

TEXT_MESSAGE_FIELDS_FRAGMENT = <<~GRAPHQL
  fragment TextMessageFields on Message {
    id
    ... on TextMessage {
      body
    }
  }
GRAPHQL

CONVERSATION_FIELDS_FRAGMENT = <<~GRAPHQL
  #{PAGE_INFO_FRAGMENT}
  #{TEXT_MESSAGE_FIELDS_FRAGMENT}
  fragment ConversationFields on Conversation {
    id
    channel {
      id
      displayName
    }
    messages {
      nodes {
        ...TextMessageFields
      }

      pageInfo {
        ...PageInfoFields
      }
    }
  }
GRAPHQL

EXPORT_ALL_CONVERSATIONS_QUERY = <<~GRAPHQL
  #{CONVERSATION_FIELDS_FRAGMENT}
  query ExportAllConversations($first: Int, $after: String) {
    app {
      conversations(first: $first, after: $after) {
        nodes {
          ...ConversationFields
        }
        pageInfo {
          ...PageInfoFields
        }
      }
    }
  }
GRAPHQL

EXPORT_ALL_MESSAGES_QUERY = <<~GRAPHQL
  #{TEXT_MESSAGE_FIELDS_FRAGMENT}
  query ExportAllMessagesQuery($conversationId: Int!, $first: Int, $after: String) {
    app {
      conversation(id: $conversationId) {
        messages(first: $first, after: $after) {
          nodes {
            ...TextMessageFields
          }
        }
      }
    }
  }
GRAPHQL
```

This section defines the necessary GraphQL fragments and queries that the script will use to fetch the conversations and messages.

**3. Function: fetch_messages_for_conversation(conversation)**

```ruby
def fetch_messages_for_conversation(conversation)
  messages = []
  should_continue = true
  after = conversation.dig("messages", "pageInfo", "endCursor")
  query = EXPORT_ALL_MESSAGES_QUERY

  while should_continue
    puts "Fetching messages #{after ? "after" : "from beginning"} for conversation #{conversation["id"]}"
    response = make_request(query, { conversationId: conversation["id"], first: 100, after: after })
    message_response = response.dig("data", "app", "conversation", "messages")
    puts "Fetched #{message_response.dig("nodes").count} messages"
    messages += message_response.dig("nodes")
    should_continue = message_response.dig("pageInfo", "hasNextPage")
    after = message_response.dig("pageInfo", "endCursor")
    sleep 5
  end

  conversation["messages"]["nodes"] += messages
end
```

This function fetches all the messages for a given conversation object. It uses a while loop to paginate through the messages, making API requests until there are no more messages to fetch. Then, it combines all fetched messages into the conversation object.

**4. Function: fetch_conversations**

```ruby
def fetch_conversations
  conversations = []
  should_continue = true
  after = nil
  query = EXPORT_ALL_CONVERSATIONS_QUERY

  while should_continue
    puts "Fetching conversations #{after ? "after #{after}" : "from beginning"}"
    response = make_request(query, { first: 100, after: after })
    conversation_response = response.dig("data", "app", "conversations")
    puts "Fetched #{conversation_response.dig("nodes").count} conversations"
    conversation_objects = conversation_response.dig("nodes")
    conversation_objects.each do |conversation|
      fetch_messages_for_conversation(conversation) if conversation.dig("messages", "pageInfo", "hasNextPage")
    end
    conversations += conversation_objects
    should_continue = conversation_response.dig("pageInfo", "hasNextPage")
    after = conversation_response.dig("pageInfo", "endCursor")
    sleep 5
  end
  File.write("conversations.json", JSON.pretty_generate(conversations))
end
```

This function fetches all the conversations and their associated messages. It uses a while loop to paginate through the conversations, making API requests until there are no more conversations to fetch. For each conversation, it calls the `fetch_messages_for_conversation` function to fetch all the messages if there are more than initially retrieved. Finally, it saves the conversations to a JSON file named `conversations.json`.

**5. Function: make_request(query, variables = {})**

```ruby
def make_request(query, variables = {})
  http = Net::HTTP.new(URL.host, URL.port)
  http.use_ssl = true
  http.verify_mode = OpenSSL::SSL::VERIFY_NONE

  request = Net::HTTP::Post.new(URL)
  request["Content-Type"] = "application/json"
  request["Authorization"] = ACCESS_TOKEN

  body = { query: query, variables: variables }
  request.body = JSON.dump(body)
  response = http.request(request)
  JSON.parse(response.read_body)
end
```

This function is a helper function to make HTTP requests to the API with the specified GraphQL query and variables. It sets up the necessary headers, creates the request body, sends the request, and parses the response.

**6. Calling the main function**

```ruby
fetch_conversations
```

This line calls the `fetch_conversations` function to start the process of fetching and exporting all conversations and their messages.

**7. Summing up**

In summary, this script fetches all conversations and their associated messages using GraphQL and the Rasayel API. It then combines the data and saves it to a JSON file named `conversations.json`. The script is organized into functions that handle fetching messages for a conversation, fetching all conversations, making API requests, and executing the main function to fetch and export the data.

### The full script

```ruby
require "uri"
require "net/http"
require "openssl"
require "json"

ACCESS_TOKEN = "YOUR ACCESS TOKEN GOES HERE" # Your Access Token goes here
URL = URI("https://api.rasayel.io/api/graphql")

PAGE_INFO_FRAGMENT = <<~GRAPHQL
  fragment PageInfoFields on PageInfo {
    hasNextPage
    endCursor
  }
GRAPHQL

TEXT_MESSAGE_FIELDS_FRAGMENT = <<~GRAPHQL
  fragment TextMessageFields on Message {
    id
    ... on TextMessage {
      body
    }
  }
GRAPHQL

CONVERSATION_FIELDS_FRAGMENT = <<~GRAPHQL
  #{PAGE_INFO_FRAGMENT}
  #{TEXT_MESSAGE_FIELDS_FRAGMENT}
  fragment ConversationFields on Conversation {
    id
    channel {
      id
      displayName
    }
    messages {
      nodes {
        ...TextMessageFields
      }

      pageInfo {
        ...PageInfoFields
      }
    }
  }
GRAPHQL

EXPORT_ALL_CONVERSATIONS_QUERY = <<~GRAPHQL
  #{CONVERSATION_FIELDS_FRAGMENT}
  query ExportAllConversations($first: Int, $after: String) {
    app {
      conversations(first: $first, after: $after) {
        nodes {
          ...ConversationFields
        }
        pageInfo {
          ...PageInfoFields
        }
      }
    }
  }
GRAPHQL

EXPORT_ALL_MESSAGES_QUERY = <<~GRAPHQL
  #{TEXT_MESSAGE_FIELDS_FRAGMENT}
  query ExportAllMessagesQuery($conversationId: Int!, $first: Int, $after: String) {
    app {
      conversation(id: $conversationId) {
        messages(first: $first, after: $after) {
          nodes {
            ...TextMessageFields
          }
        }
      }
    }
  }
GRAPHQL

def fetch_messages_for_conversation(conversation)
  messages = []
  should_continue = true
  after = conversation.dig("messages", "pageInfo", "endCursor")
  query = EXPORT_ALL_MESSAGES_QUERY

  while should_continue
    puts "Fetching messages #{after ? "after" : "from beginning"} for conversation #{conversation["id"]}"
    response = make_request(query, { conversationId: conversation["id"], first: 100, after: after })
    message_response = response.dig("data", "app", "conversation", "messages")
    puts "Fetched #{message_response.dig("nodes").count} messages"
    messages += message_response.dig("nodes")
    should_continue = message_response.dig("pageInfo", "hasNextPage")
    after = message_response.dig("pageInfo", "endCursor")
    sleep 5
  end

  conversation["messages"]["nodes"] += messages
end

def fetch_conversations
  conversations = []
  should_continue = true
  after = nil
  query = EXPORT_ALL_CONVERSATIONS_QUERY

  while should_continue
    puts "Fetching conversations #{after ? "after #{after}" : "from beginning"}"
    response = make_request(query, { first: 100, after: after })
    conversation_response = response.dig("data", "app", "conversations")
    puts "Fetched #{conversation_response.dig("nodes").count} conversations"
    conversation_objects = conversation_response.dig("nodes")
    conversation_objects.each do |conversation|
      fetch_messages_for_conversation(conversation) if conversation.dig("messages", "pageInfo", "hasNextPage")
    end
    conversations += conversation_objects
    should_continue = conversation_response.dig("pageInfo", "hasNextPage")
    after = conversation_response.dig("pageInfo", "endCursor")
    sleep 5
  end
  File.write("conversations.json", JSON.pretty_generate(conversations))
end

def make_request(query, variables = {})
  http = Net::HTTP.new(URL.host, URL.port)
  http.use_ssl = true
  http.verify_mode = OpenSSL::SSL::VERIFY_NONE

  request = Net::HTTP::Post.new(URL)
  request["Content-Type"] = "application/json"
  request["Authorization"] = ACCESS_TOKEN

  body = { query: query, variables: variables }
  request.body = JSON.dump(body)
  response = http.request(request)
  JSON.parse(response.read_body)
end

fetch_conversations
```
